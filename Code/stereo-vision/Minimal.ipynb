{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee44a05b",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import copy\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49067d0f",
   "metadata": {},
   "source": [
    "File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_data_path = \"/mnt/Personal/Projects/Depth_Reconstruction/Test_Folder/stereo_test/test_images/stereo.pkl\"\n",
    "disparity_data_path = \"/mnt/Personal/Projects/Depth_Reconstruction/Model_Output/runtime/disparity.pkl\"\n",
    "smoothed_data_path = \"/mnt/Personal/Projects/Depth_Reconstruction/Model_Output/runtime/smoothed.pkl\"\n",
    "\n",
    "# stereo_data_path = \"/kaggle/input/stereo-dataset-middlebury2014-input/stereo.pkl\"\n",
    "# disparity_data_path = \"/kaggle/working/disparity.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57515ade",
   "metadata": {},
   "source": [
    "Accessory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    dict: The loaded dictionary with structure for stereo data:\n",
    "        {\n",
    "            \"folder1\": {\n",
    "                \"order\": int,\n",
    "                \"im0\": numpy array,\n",
    "                \"im1\": numpy array,\n",
    "                \"calib\": int\n",
    "            },\n",
    "            \"folder2\": { ... },\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "def load_pickle(pickle_path):\n",
    "    \n",
    "    if not os.path.exists(pickle_path):\n",
    "        raise FileNotFoundError(f\"Pickle file not found at: {pickle_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "    \n",
    "    except pickle.UnpicklingError as e:\n",
    "        raise pickle.UnpicklingError(f\"Failed to unpickle file: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading pickle file: {str(e)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(var, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(var, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c623b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_mono(img_array):\n",
    "    \"\"\"Convert RGB image array to luminance (grayscale) using standard weights.\"\"\"\n",
    "    if len(img_array.shape) == 2:\n",
    "        return img_array  # Already grayscale\n",
    "    gray = np.dot(img_array[..., :3], [4, 4, 4])\n",
    "    return gray.astype(np.int_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76281352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_array(image_array, scale_factor):\n",
    "    # Convert array to PIL Image\n",
    "    if len(image_array.shape) == 2:\n",
    "        # Grayscale image\n",
    "        img = Image.fromarray(image_array)\n",
    "    elif len(image_array.shape) == 3:\n",
    "        # RGB/RGBA image\n",
    "        img = Image.fromarray(image_array.astype('uint8'))\n",
    "    else:\n",
    "        raise ValueError(\"Input array must be 2D (grayscale) or 3D (color)\")\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    width, height = img.size\n",
    "    new_width = int(width * scale_factor)\n",
    "    new_height = int(height * scale_factor)\n",
    "    \n",
    "    # Resize using Lanczos resampling (high quality)\n",
    "    resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Convert back to numpy array\n",
    "    resized_array = np.array(resized_img)\n",
    "    \n",
    "    # Preserve original dtype for grayscale\n",
    "    if len(image_array.shape) == 2:\n",
    "        resized_array = resized_array.astype(image_array.dtype)\n",
    "    \n",
    "    return resized_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a17755",
   "metadata": {},
   "source": [
    "Texture Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefc4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def texture_segmentation(counter,image, threshold, disable=False):\n",
    "    \n",
    "    h, w = image.shape\n",
    "    output = np.zeros_like(image, dtype=int)\n",
    "    texture_label = 1\n",
    "    texture_dict = defaultdict(list)\n",
    "    \n",
    "    # Create list of all possible coordinates\n",
    "    all_coords = [(y, x) for y in range(h) for x in range(w)]\n",
    "    random.shuffle(all_coords)  # Randomize processing order\n",
    "    \n",
    "    with tqdm(total=h*w, desc=f\"(Order - {counter}) Segmenting Textures\", disable=disable) as pbar:\n",
    "        for y, x in all_coords:\n",
    "            if output[y, x] != 0:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "                \n",
    "            org_value = image[y, x]\n",
    "            stack = [(y, x)]\n",
    "            pixels_processed = 0\n",
    "            \n",
    "            # Perform flood fill\n",
    "            while stack:\n",
    "                cy, cx = stack.pop()\n",
    "                if output[cy, cx] != 0:\n",
    "                    continue\n",
    "                    \n",
    "                output[cy, cx] = texture_label\n",
    "                texture_dict[texture_label].append((cy, cx))\n",
    "                pixels_processed += 1\n",
    "                \n",
    "                # Check 4-connected neighbors\n",
    "                for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                    ny, nx = cy + dy, cx + dx\n",
    "                    if (0 <= ny < h and 0 <= nx < w and \n",
    "                        output[ny, nx] == 0 and \n",
    "                        abs(int(image[ny, nx]) - int(org_value)) <= threshold):\n",
    "                        stack.append((ny, nx))\n",
    "            \n",
    "            texture_label += 1\n",
    "            pbar.update(pixels_processed)\n",
    "    \n",
    "    return output, texture_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a925090",
   "metadata": {},
   "source": [
    "Generating Disparity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_disparity(file_name, counter, image_l, image_r, text_dict, search_range,disable=False):\n",
    "    \n",
    "    # Validate inputs\n",
    "    assert image_l.shape == image_r.shape, \"Images must have the same shape\"\n",
    "    h, w = image_l.shape\n",
    "    disparity = np.zeros((h, w), dtype=int)\n",
    "    \n",
    "    # Pre-compute all possible right window shifts\n",
    "    shifts = np.arange(search_range)\n",
    "    \n",
    "    for tex in tqdm(text_dict, desc=f\"(Order - {counter} )Generating Disparity for {file_name}\",disable=disable):\n",
    "        coords = np.array(text_dict[tex])\n",
    "        i, j = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Compute all possible right windows at once\n",
    "        j_shifted = j.reshape(-1, 1) - shifts.reshape(1, -1)\n",
    "        \n",
    "        # Mask for valid coordinates\n",
    "        valid_mask = (j_shifted >= 0) & (j_shifted < w)\n",
    "        all_valid = valid_mask.all(axis=0)\n",
    "        \n",
    "        # Initialize SAD values with infinity (for invalid shifts)\n",
    "        sad_values = np.full(search_range, np.inf)\n",
    "        \n",
    "        # Compute SAD only for valid shifts\n",
    "        for k in np.where(all_valid)[0]:\n",
    "            right_j = j - k\n",
    "            # Vectorized SAD computation\n",
    "            diff = image_l[coords[:, 0], coords[:, 1]] - image_r[coords[:, 0], right_j]\n",
    "            sad_values[k] = np.mean(np.abs(diff))\n",
    "        \n",
    "        # Find best disparity (minimum SAD)\n",
    "        if not np.all(np.isinf(sad_values)):\n",
    "            best_disparity = np.argmin(sad_values)\n",
    "            disparity[coords[:, 0], coords[:, 1]] = best_disparity\n",
    "    \n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def52df1",
   "metadata": {},
   "source": [
    "Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "def post_process_texture(disp_matrix, texture, threshold_percent):\n",
    "    \n",
    "    if disp_matrix.shape != texture.shape:\n",
    "        raise ValueError(\"disp_matrix and texture must have the same shape\")\n",
    "    \n",
    "    rows, cols = disp_matrix.shape\n",
    "    processed = np.zeros_like(texture, dtype=bool)\n",
    "    directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "    \n",
    "    # Create a view for faster access\n",
    "    texture_flat = texture.ravel()\n",
    "    disp_flat = disp_matrix.ravel()\n",
    "    processed_flat = processed.ravel()\n",
    "    \n",
    "    for idx in range(len(texture_flat)):\n",
    "        if processed_flat[idx]:\n",
    "            continue\n",
    "            \n",
    "        current_texture = texture_flat[idx]\n",
    "        queue = deque([idx])\n",
    "        region_indices = []\n",
    "        \n",
    "        # BFS using flat indices\n",
    "        while queue:\n",
    "            flat_idx = queue.popleft()\n",
    "            if not processed_flat[flat_idx]:\n",
    "                processed_flat[flat_idx] = True\n",
    "                region_indices.append(flat_idx)\n",
    "                \n",
    "                # Convert to 2D coordinates for neighbor checking\n",
    "                x, y = np.unravel_index(flat_idx, (rows, cols))\n",
    "                \n",
    "                for dx, dy in directions:\n",
    "                    nx, ny = x + dx, y + dy\n",
    "                    if 0 <= nx < rows and 0 <= ny < cols:\n",
    "                        neighbor_idx = np.ravel_multi_index((nx, ny), (rows, cols))\n",
    "                        if (not processed_flat[neighbor_idx] and \n",
    "                            texture_flat[neighbor_idx] == current_texture):\n",
    "                            queue.append(neighbor_idx) # type: ignore\n",
    "        \n",
    "        # Process the region\n",
    "        if region_indices:\n",
    "            region_disps = disp_flat[region_indices]\n",
    "            median_disp = np.median(region_disps)\n",
    "            threshold = median_disp * threshold_percent\n",
    "            \n",
    "            # Vectorized outlier detection and replacement\n",
    "            outliers = np.abs(region_disps - median_disp) > threshold\n",
    "            disp_flat[region_indices] = np.where(outliers, median_disp, region_disps)\n",
    "    \n",
    "    return disp_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894c285c",
   "metadata": {},
   "source": [
    "Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_runner(file_name, stereo_dict,resize):\n",
    "    \n",
    "    image_array_l = stereo_dict[\"im0\"]\n",
    "    image_array_r = stereo_dict[\"im1\"]\n",
    "    calib_dim = stereo_dict[\"calib\"]\n",
    "    \n",
    "    \n",
    "    resize_scale = resize\n",
    "\n",
    "    rgb_l = resize_image_array(image_array_l,resize_scale)\n",
    "    rgb_r = resize_image_array(image_array_r,resize_scale)\n",
    "\n",
    "    # maximum colour density is now 1020\n",
    "\n",
    "    gray_array_l = rgb_to_mono(rgb_l)\n",
    "    gray_array_r = rgb_to_mono(rgb_r)\n",
    "\n",
    "\n",
    "    # print(\"Image Shape - \",gray_array_l.shape)\n",
    "    # print(\"Total Pixels - \",(gray_array_l.shape[0]*gray_array_l.shape[1]))\n",
    "\n",
    "    texture,texture_dict = texture_segmentation(stereo_dict[\"order\"],gray_array_l,20,disable=False)\n",
    "\n",
    "    search = round(calib_dim*resize_scale)\n",
    "\n",
    "    disp_matrix = generate_disparity(file_name, stereo_dict[\"order\"], gray_array_l,gray_array_r,texture_dict,search,disable=False)\n",
    "\n",
    "    # print(\"Search Distance - \",search)\n",
    "\n",
    "    smoothed = copy.deepcopy(disp_matrix)\n",
    "\n",
    "    post_process_iteration = 4\n",
    "\n",
    "    for _ in tqdm(range(post_process_iteration), desc=\"Post Processing\",disable=True):\n",
    "        texture,_ = texture_segmentation(stereo_dict[\"order\"],gray_array_l,100,disable=True)\n",
    "        smoothed = post_process_texture(smoothed,texture, 0.07)\n",
    "        \n",
    "    return (disp_matrix,smoothed)\n",
    "\n",
    "    # plot_viridis_matrix(disp_matrix)\n",
    "    # plot_viridis_matrix(smoothed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8108f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_wrapper(args):\n",
    "    folder, data, resize = args\n",
    "    multiprocessing.current_process().name = f\"Processing {folder}\"\n",
    "    \n",
    "    result = single_runner(folder, data, resize)\n",
    "    \n",
    "    returner = (folder,result[0],result[1])\n",
    "    \n",
    "    return returner\n",
    "\n",
    "def parallel_process_stereo_data(stereo_data, resize, num_processes=None):\n",
    "\n",
    "    if num_processes is None:\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "    \n",
    "    disparity_dict = defaultdict(dict)\n",
    "    smoothed_dict = defaultdict(dict)\n",
    "    \n",
    "    # Prepare arguments for multiprocessing\n",
    "    args = [(folder, stereo_data[folder], resize) for folder in stereo_data]\n",
    "    \n",
    "    # Create a pool of workers\n",
    "    with multiprocessing.Pool(processes=num_processes, \n",
    "                            initializer=tqdm.set_lock, \n",
    "                            initargs=(multiprocessing.RLock(),)) as pool:\n",
    "        \n",
    "        # Use imap_unordered for faster processing with progress updates\n",
    "        results = list(tqdm(pool.imap_unordered(process_wrapper, args),\n",
    "                      total=len(stereo_data),\n",
    "                      desc=\"Executing Files\"))\n",
    "        \n",
    "        # Collect results\n",
    "        for result in results:\n",
    "            folder = result[0]\n",
    "            disp = result[1]\n",
    "            smooth = result[2]\n",
    "            disparity_dict[folder] = disp  # type: ignore\n",
    "            smoothed_dict[folder] = smooth # type: ignore\n",
    "    \n",
    "    return dict(disparity_dict),dict(smoothed_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611316a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stereo_data_org = load_pickle(stereo_data_path)\n",
    "stereo_data={}\n",
    "\n",
    "key_set=[]\n",
    "\n",
    "for key in stereo_data_org:\n",
    "    key_set.append(key)\n",
    "    \n",
    "key_set=key_set[:50]\n",
    "\n",
    "for key in key_set:\n",
    "    stereo_data[key]= stereo_data_org[key]\n",
    "    \n",
    "\n",
    "\n",
    "disparity_dict={}\n",
    "\n",
    "resize = 1\n",
    "\n",
    "\n",
    "disparity_dict,smoothed_dict = parallel_process_stereo_data(stereo_data, resize)\n",
    "    \n",
    "save_pickle(disparity_dict,disparity_data_path)\n",
    "save_pickle(smoothed_dict,smoothed_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14077a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stereo_data = load_pickle(stereo_data_path)\n",
    "\n",
    "# disparity_dict={}\n",
    "\n",
    "# resize = 0.0625\n",
    "\n",
    "\n",
    "# for folder in tqdm(stereo_data,desc=\"Executing Files\"):\n",
    "    \n",
    "#     disparity_dict[folder] = single_runner(stereo_data[folder],resize)\n",
    "    \n",
    "# save_pickle = save_pickle(disparity_dict,disparity_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_viridis_matrix(matrix1, matrix2, title1='Disparity', title2='Smoothed'):\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # First subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(matrix1, cmap='viridis')\n",
    "    plt.title(title1)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Second subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(matrix2, cmap='viridis')\n",
    "    plt.title(title2)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()  # Prevent title overlap\n",
    "    plt.show()\n",
    "    \n",
    "temp_disp = load_pickle(disparity_data_path)\n",
    "temp_smooth = load_pickle(smoothed_data_path)\n",
    "    \n",
    "for key in key_set:\n",
    "    plot_viridis_matrix(disparity_dict[key],smoothed_dict[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
