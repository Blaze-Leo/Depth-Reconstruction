{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path=\"/mnt/Velocity_Vault/Code/Depth_Estimation/\"\n",
    "\n",
    "test_input_path=org_path+\"Marigold/test_folders/test_images/\"\n",
    "test_output_path=org_path+\"Marigold/test_folders/test_outputs/\"\n",
    "test_3d_path=org_path+\"Marigold/test_folders/test_3d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Extra/Virtual_Environment/Marigold/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/mnt/Extra/Virtual_Environment/Marigold/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caba2f498e6445f2a56063b4ceaedd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import diffusers\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import cv2\n",
    "\n",
    "depth_pipe = diffusers.MarigoldDepthPipeline.from_pretrained(\"prs-eth/marigold-depth-lcm-v1-0\",\n",
    "                                                        variant=\"fp16\",\n",
    "                                                        torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "# normal_pipe = diffusers.MarigoldNormalsPipeline.from_pretrained(\"prs-eth/marigold-depth-lcm-v1-0\",\n",
    "#                                                         variant=\"fp16\",\n",
    "#                                                         torch_dtype=torch.float16).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_image(image, target):\n",
    "    \"\"\"\n",
    "    Downscales an image by a given scale factor.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image array (H, W) or (H, W, C).\n",
    "        scale (float): Scale factor (e.g., 0.5 for half size, 2 for double).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Resized image.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    x_res=image.shape[1]\n",
    "    y_res=image.shape[0]\n",
    "    \n",
    "    if target>=max(x_res,y_res):\n",
    "        return image\n",
    "    \n",
    "    factor=0\n",
    "    \n",
    "    if x_res==max(x_res,y_res):\n",
    "        factor=x_res/target\n",
    "        x_res=target\n",
    "        y_res=y_res/factor\n",
    "        \n",
    "    elif y_res==max(x_res,y_res):\n",
    "        factor=y_res/target\n",
    "        y_res=target\n",
    "        x_res=x_res/factor\n",
    "    \n",
    "\n",
    "    new_size = (int(x_res), int(y_res))  # (width, height)\n",
    "    \n",
    "    downscaled = cv2.resize(image, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncertainity=depth.uncertainty[0]\n",
    "# from pprint import pprint\n",
    "# # pprint(uncertainity)\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_array(data, cmap=\"viridis\"):\n",
    "#     \"\"\"\n",
    "#     Plots a 2D array with values ranging from 0 to 1.\n",
    "    \n",
    "#     Parameters:\n",
    "#         data (numpy.ndarray): 2D array with values in [0,1].\n",
    "#         cmap (str): Colormap for visualization.\n",
    "#     \"\"\"\n",
    "#     plt.imshow(data, cmap=cmap, vmin=0, vmax=np.mean(data))\n",
    "#     plt.colorbar(label=\"Value\")\n",
    "#     plt.axis(\"off\")  # Hide axes\n",
    "#     plt.show()\n",
    "\n",
    "# plot_array(uncertainity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import trimesh\n",
    "# import open3d as o3d\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "\n",
    "# def create_3d_mesh(depth_map, color_image=None, scale=1.0, threshold=0.1,apply_colour=True):\n",
    "#     \"\"\"\n",
    "#     Generates a 3D mesh from a depth map and applies color from the original image.\n",
    "\n",
    "#     Parameters:\n",
    "#         depth_map (numpy.ndarray): 2D array of depth values in the range [0,1].\n",
    "#         color_image (numpy.ndarray): Corresponding 2D image (H, W, 3) with RGB colors.\n",
    "#         scale (float): Factor to scale depth values.\n",
    "#         threshold (float): Maximum depth difference allowed between nearby points for face creation.\n",
    "\n",
    "#     Returns:\n",
    "#         open3d.geometry.TriangleMesh: The 3D mesh object.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     H, W = depth_map.shape\n",
    "#     vertices = []\n",
    "#     colors = []\n",
    "#     faces = []\n",
    "\n",
    "#     # Generate vertices and colors\n",
    "#     for y in tqdm(range(H)):\n",
    "#         for x in range(W):\n",
    "#             z = depth_map[y, x] * scale  # Scale the depth\n",
    "#             vertices.append([x, -y, z])  # Flip Y-axis for correct orientation\n",
    "#             colors.append(color_image[y, x] / 255.0)  # Normalize RGB\n",
    "\n",
    "#     vertices = np.array(vertices)\n",
    "#     colors = np.array(colors)\n",
    "\n",
    "#     # Generate faces (triangles)\n",
    "#     def get_index(x, y):\n",
    "#         return y * W + x  # Compute index in a 1D list\n",
    "\n",
    "#     for y in tqdm(range(H - 1)):\n",
    "#         for x in range(W - 1):\n",
    "#             i1 = get_index(x, y)\n",
    "#             i2 = get_index(x + 1, y)\n",
    "#             i3 = get_index(x, y + 1)\n",
    "#             i4 = get_index(x + 1, y + 1)\n",
    "\n",
    "#             # Check depth differences\n",
    "#             if abs(depth_map[y, x] - depth_map[y, x + 1]) < threshold and \\\n",
    "#                 abs(depth_map[y, x] - depth_map[y + 1, x]) < threshold:\n",
    "#                 faces.append([i1, i2, i3])  # Triangle 1\n",
    "\n",
    "#             if abs(depth_map[y + 1, x + 1] - depth_map[y, x + 1]) < threshold and \\\n",
    "#                 abs(depth_map[y + 1, x + 1] - depth_map[y + 1, x]) < threshold:\n",
    "#                 faces.append([i2, i4, i3])  # Triangle 2\n",
    "\n",
    "#     faces = np.array(faces)\n",
    "\n",
    "#     # Create Open3D mesh\n",
    "#     mesh = o3d.geometry.TriangleMesh()\n",
    "#     mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "#     mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "#     if apply_colour:\n",
    "#         mesh.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "#     return mesh\n",
    "\n",
    "# # Load depth map and color image\n",
    "# # depth_map = np.array(Image.open(\"depth_map.png\").convert(\"L\")) / 255.0  # Normalize [0,1]\n",
    "# # color_image = np.array(Image.open(\"color_image.png\"))\n",
    "\n",
    "# image_array=np.array(image)\n",
    "\n",
    "# # Generate 3D mesh\n",
    "# mesh = create_3d_mesh(depth_array, color_image=image_array, scale=700, threshold=10e-3,apply_colour=False)\n",
    "\n",
    "# # Save and visualize\n",
    "# image_3d_name=image_name[:image_name.rfind('.')]+\".ply\"\n",
    "# o3d.io.write_triangle_mesh(test_3d_path+image_3d_name, mesh)\n",
    "# print(f\"Saved as {image_3d_name}\")\n",
    "# # o3d.visualization.draw_geometries([mesh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import KDTree \n",
    "\n",
    "def fill_3d_mesh(depth_map, origin=(0,0,0),color_image=None, scale=1.0, threshold=0.1, euclid_threshold=1.5, apply_colour=True):\n",
    "    \"\"\"\n",
    "    Generates a 3D mesh from a depth map and applies color from the original image.\n",
    "    Filters out unused points and connects points within a Euclidean distance using KD-Tree.\n",
    "\n",
    "    Parameters:\n",
    "        depth_map (numpy.ndarray): 2D array of depth values in the range [0,1].\n",
    "        color_image (numpy.ndarray): Corresponding 2D image (H, W, 3) with RGB colors.\n",
    "        scale (float): Factor to scale depth values.\n",
    "        threshold (float): Maximum depth difference allowed between nearby points for face creation.\n",
    "        euclid_threshold (float): Maximum Euclidean distance to create additional triangles.\n",
    "        apply_colour (bool): Whether to apply vertex colors.\n",
    "\n",
    "    Returns:\n",
    "        open3d.geometry.TriangleMesh: The 3D mesh object.\n",
    "    \"\"\"\n",
    "    \n",
    "    H, W = depth_map.shape\n",
    "    vertices = []\n",
    "    colors = []\n",
    "    faces = []\n",
    "    index_map = np.full((H, W), -1, dtype=int)  # Keeps track of valid vertices\n",
    "    \n",
    "    vertices.append([origin[0], -origin[1], origin[2]])\n",
    "\n",
    "    # Generate valid vertices and store their index mapping\n",
    "    for y in tqdm(range(H)):\n",
    "        for x in range(W):\n",
    "            z = depth_map[y, x] * scale  # Scale depth\n",
    "            if z > 0:  # Ensure valid depth\n",
    "                index_map[y, x] = len(vertices)  # Store new index\n",
    "                vertices.append([x+origin[0], -(y+origin[1]), z+origin[2]])  # Flip Y-axis for correct orientation\n",
    "                if apply_colour:\n",
    "                    colors.append(color_image[y, x] / 255.0)  # Normalize RGB\n",
    "\n",
    "    vertices = np.array(vertices)\n",
    "    colors = np.array(colors) if apply_colour else None\n",
    "\n",
    "    # Generate faces with threshold check\n",
    "    for y in tqdm(range(H - 1)):\n",
    "        for x in range(W - 1):\n",
    "            i1 = index_map[y, x]\n",
    "            i2 = index_map[y, x + 1]\n",
    "            i3 = index_map[y + 1, x]\n",
    "            i4 = index_map[y + 1, x + 1]\n",
    "\n",
    "            if i1 == -1 or i2 == -1 or i3 == -1 or i4 == -1:\n",
    "                continue  # Skip invalid points\n",
    "\n",
    "            # Check depth differences\n",
    "            if abs(depth_map[y, x] - depth_map[y, x + 1]) < threshold and \\\n",
    "               abs(depth_map[y, x] - depth_map[y + 1, x]) < threshold:\n",
    "                faces.append([i1, i2, i3])  # Triangle 1\n",
    "\n",
    "            if abs(depth_map[y + 1, x + 1] - depth_map[y, x + 1]) < threshold and \\\n",
    "               abs(depth_map[y + 1, x + 1] - depth_map[y + 1, x]) < threshold:\n",
    "                faces.append([i2, i4, i3])  # Triangle 2\n",
    "\n",
    "    # **Optimized Neighbor Search Using KD-Tree**\n",
    "    # print(\"Building KD-Tree for fast neighbor search...\")\n",
    "    tree = KDTree(vertices)  # Precompute KD-Tree\n",
    "\n",
    "    # print(\"Finding additional connections...\")\n",
    "    for i in tqdm(range(len(vertices))):\n",
    "        # Find neighbors within euclid_threshold\n",
    "        indices = tree.query_ball_point(vertices[i], euclid_threshold)\n",
    "        for j in indices:\n",
    "            if j > i:  # Avoid duplicate triangles\n",
    "                faces.append([i, j, (i + 1) % len(vertices)])\n",
    "\n",
    "    faces = np.array(faces)\n",
    "\n",
    "    # Create Open3D mesh\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "    mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "    if apply_colour:\n",
    "        mesh.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    return mesh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import open3d as o3d\n",
    "# import numpy as np\n",
    "\n",
    "# def transpose_ply_axes(ply_path, output_path, axis_order):\n",
    "#     # Load the PLY file\n",
    "#     mesh = o3d.io.read_triangle_mesh(ply_path)\n",
    "#     vertices = np.asarray(mesh.vertices)\n",
    "    \n",
    "#     # Apply the axis transformation\n",
    "#     vertices = vertices[:, list(axis_order)]  # Reorder axes\n",
    "\n",
    "#     # Update the mesh with new vertex positions\n",
    "#     mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "\n",
    "#     # Save the modified PLY file\n",
    "#     o3d.io.write_triangle_mesh(output_path, mesh)\n",
    "\n",
    "# # Example usage:\n",
    "# # transpose_ply_axes(test_3d_path+image_3d_name, test_3d_path+image_3d_name, (0, 2, 1))  # Swap X ↔ Z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# depth_map = np.array(...)  # Load depth map (H, W)\n",
    "# color_image = np.array(...)  # Load color image (H, W, 3)\n",
    "# mesh = fill_3d_mesh(depth_map, color_image, scale=10, threshold=0.1, euclid_threshold=1.5)\n",
    "# o3d.visualization.draw_geometries([mesh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation (Very High RAM usage)\n",
    "# import trimesh\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def segment_and_color_mesh(mesh_path, output_path=\"segmented_mesh.obj\"):\n",
    "#     \"\"\"\n",
    "#     Segments a 3D mesh into separate components and colors each part differently.\n",
    "\n",
    "#     Parameters:\n",
    "#         mesh_path (str): Path to the input 3D model file.\n",
    "#         output_path (str): Path to save the segmented model.\n",
    "#         threshold (float): Distance threshold for considering components as separate.\n",
    "    \n",
    "#     Returns:\n",
    "#         trimesh.Trimesh: The segmented and colored mesh.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Load mesh\n",
    "    \n",
    "#     mesh = trimesh.load_mesh(mesh_path)\n",
    "\n",
    "#     # Find connected components\n",
    "#     mesh.merge_vertices()\n",
    "#     components = mesh.split(only_watertight=False)  # Allow non-watertight parts\n",
    "\n",
    "#     print(f\"Found {len(components)} separate objects in the mesh.\")\n",
    "\n",
    "#     # Assign colors to each component\n",
    "#     colored_meshes = []\n",
    "#     for comp in components:\n",
    "#         if len(comp.vertices) == 0:\n",
    "#             continue  # Skip empty components\n",
    "\n",
    "#         # Generate a random color for each part\n",
    "#         color = np.array([random.random(), random.random(), random.random(), 1.0])  # RGBA\n",
    "#         comp.visual.vertex_colors = color  # Apply color\n",
    "\n",
    "#         colored_meshes.append(comp)\n",
    "\n",
    "#     # Merge all parts back into one mesh\n",
    "#     segmented_mesh = trimesh.util.concatenate(colored_meshes)\n",
    "\n",
    "#     # Save the colored segmented mesh\n",
    "#     segmented_mesh.export(output_path)\n",
    "#     print(f\"Segmented mesh saved to {output_path}\")\n",
    "\n",
    "#     return segmented_mesh\n",
    "\n",
    "# # Example usage:\n",
    "# # segmented_mesh = segment_and_color_mesh(\"your_model.ply\", \"output.ply\", threshold=50)\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# # mesh = highlight_disconnected_parts(\"your_model.ply\", threshold=200)\n",
    "# # o3d.visualization.draw_geometries([mesh])\n",
    "\n",
    "\n",
    "# seperate_3d_name=\"disconnected_\"+image_name[:image_name.rfind('.')]+\".ply\"\n",
    "\n",
    "# mesh = segment_and_color_mesh(test_3d_path+image_3d_name, output_path=test_3d_path+seperate_3d_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open3d as o3d\n",
    "# import numpy as np\n",
    "\n",
    "# def read_vertices_from_ply(ply_file):\n",
    "#     mesh = o3d.io.read_triangle_mesh(ply_file)\n",
    "#     vertices = np.asarray(mesh.vertices)  # Convert to NumPy array\n",
    "#     return vertices\n",
    "\n",
    "# # Example usage\n",
    "# ply_file = test_3d_path+\"filled_leg_up.ply\"\n",
    "# vertices = read_vertices_from_ply(ply_file)\n",
    "# pprint(vertices)  # Prints the vertex coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def load_ply(ply_path):\n",
    "    \"\"\"Loads a PLY file and returns vertices and colors.\"\"\"\n",
    "    mesh = o3d.io.read_triangle_mesh(ply_path)\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    colors = np.asarray(mesh.vertex_colors) if mesh.has_vertex_colors() else None\n",
    "    return vertices, colors, mesh.triangles\n",
    "\n",
    "def save_ply(vertices, colors, triangles, output_path):\n",
    "    \"\"\"Saves the combined mesh as a PLY file.\"\"\"\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
    "    mesh.triangles = o3d.utility.Vector3iVector(triangles)\n",
    "    if colors is not None:\n",
    "        mesh.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.io.write_triangle_mesh(output_path, mesh)\n",
    "\n",
    "def find_mean_z_at_xy(vertices, x, y):\n",
    "    \"\"\"Finds the mean Z value of all (x, y) points in the given vertices.\"\"\"\n",
    "    matching_points = [v[2] for v in vertices if np.isclose(v[0], x) and np.isclose(v[1], y)]\n",
    "    return np.mean(matching_points) if matching_points else None\n",
    "\n",
    "def transform_model(vertices, rotation, offset, pivot):\n",
    "    \"\"\"Rotates and offsets the model around a pivot point.\"\"\"\n",
    "    rx, ry, rz = np.radians(rotation)  # Convert degrees to radians\n",
    "    rotation_matrix = R.from_euler('xyz', [rx, ry, rz], degrees=False).as_matrix()\n",
    "\n",
    "    # Translate to pivot, rotate, then translate back\n",
    "    transformed_vertices = []\n",
    "    for v in vertices:\n",
    "        v_shifted = v - pivot  # Move to pivot\n",
    "        v_rotated = rotation_matrix @ v_shifted  # Apply rotation\n",
    "        v_transformed = v_rotated + pivot + offset  # Move back and apply offset\n",
    "        transformed_vertices.append(v_transformed)\n",
    "\n",
    "    return np.array(transformed_vertices)\n",
    "\n",
    "def combine_ply_models(ply1, ply2, output_path, rotation, offset, pivot_xy):\n",
    "    \n",
    "    pivot_xy=(pivot_xy[0],-pivot_xy[1])\n",
    "    \"\"\"Combines two PLY models after transforming the second one.\"\"\"\n",
    "    # Load both PLY files\n",
    "    vertices1, colors1, faces1 = load_ply(ply1)\n",
    "    vertices2, colors2, faces2 = load_ply(ply2)\n",
    "\n",
    "    # Set the first model's origin at (0,0,0)\n",
    "    # pivot_point = np.mean(vertices1, axis=0)\n",
    "\n",
    "    # Find pivot Z in the second model\n",
    "    pivot_z = find_mean_z_at_xy(vertices2, *pivot_xy)\n",
    "    if pivot_z is None:\n",
    "        raise ValueError(f\"Point {pivot_xy} not found in second model!\")\n",
    "\n",
    "    pivot = np.array([*pivot_xy, pivot_z])\n",
    "\n",
    "    # Transform the second model\n",
    "    transformed_vertices2 = transform_model(vertices2, rotation, offset, pivot)\n",
    "\n",
    "    # Merge models\n",
    "    combined_vertices = np.vstack([vertices1, transformed_vertices2])\n",
    "    if colors1 is not None and colors2 is not None:\n",
    "        combined_colors = np.vstack([colors1, colors2])\n",
    "    else:\n",
    "        combined_colors = None\n",
    "\n",
    "    offset_faces2 = np.asarray(faces2) + len(vertices1)  # Adjust face indices\n",
    "    combined_faces = np.vstack([faces1, offset_faces2])\n",
    "\n",
    "    # Save combined model\n",
    "    save_ply(combined_vertices, combined_colors, combined_faces, output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74afa22033e94f638908fd4d4067418d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Marigold predictions...:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a08eb9b1a34e2b997586835aac2ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Diffusion steps...:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_name=\"pyramid.jpg\"\n",
    "\n",
    "image_path=test_input_path+image_name\n",
    "output_path=test_output_path+image_name\n",
    "\n",
    "image=Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# image=diffusers.utils.load_image(\"https://marigoldmonodepth.github.io/images/einstein.jpg\")\n",
    "\n",
    "image=downscale_image(np.array(image),768)\n",
    "\n",
    "depth=depth_pipe(image)\n",
    "# depth=depth_pipe(image,num_inference_steps=1,ensemble_size=3,output_uncertainty=True)\n",
    "# normal=normal_pipe(image)\n",
    "\n",
    "vis=depth_pipe.image_processor.visualize_depth(depth.prediction)\n",
    "# nor=normal_pipe.image_processor.visualize_normals(normal.prediction)\n",
    "\n",
    "vis[0].save(test_output_path+\"depth_\"+image_name)\n",
    "# nor[0].save(test_output_path+\"normal_\"+image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512, 768)\n",
      "0.0\n",
      "0.99316406\n"
     ]
    }
   ],
   "source": [
    "print(type(depth.prediction))\n",
    "# print(depth.prediction)\n",
    "depth_array=depth.prediction\n",
    "depth_array=1-depth_array\n",
    "\n",
    "depth_array=np.array([[y[0] for y in x] for x in depth_array[0]])\n",
    "\n",
    "print(depth_array.shape)\n",
    "print(np.min(depth_array))\n",
    "print(np.max(depth_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 891.82it/s]\n",
      "100%|██████████| 511/511 [00:01<00:00, 500.56it/s]\n",
      "100%|██████████| 393171/393171 [00:01<00:00, 199198.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as filled_pyramid.ply\n"
     ]
    }
   ],
   "source": [
    "image_array=np.array(image)\n",
    "\n",
    "\n",
    "mesh = fill_3d_mesh(depth_array, color_image=image_array, scale=700, threshold=10e-3, euclid_threshold=0.1,apply_colour=False)\n",
    "\n",
    "image_3d_name=\"filled_\"+image_name[:image_name.rfind('.')]+\".ply\"\n",
    "o3d.io.write_triangle_mesh(test_3d_path+image_3d_name, mesh)\n",
    "\n",
    "print(f\"Saved as {image_3d_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as filled_damn.ply\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "combine_ply_models(\n",
    "    test_3d_path+\"filled_pyramid.ply\", test_3d_path+\"filled_leg_up.ply\",test_3d_path+\"filled_damn.ply\",\n",
    "    rotation=(0, 360, 0), offset=(0, 700, 0), pivot_xy=(100, 100)\n",
    ")\n",
    "\n",
    "print(\"Saved as filled_damn.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Marigold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
